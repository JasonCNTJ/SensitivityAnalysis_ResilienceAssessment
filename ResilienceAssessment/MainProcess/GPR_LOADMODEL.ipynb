{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 导入数据\n",
    "params = np.loadtxt('0915params_2475year.txt')\n",
    "edpResults = np.loadtxt('0915edpResult_2475year.txt')\n",
    "\n",
    "params = params[:, (1, 2, 3, 4, 5, 6, 7, 8, 10)]\n",
    "edpResults = np.log(edpResults)\n",
    "params_ridr = np.hstack((params, edpResults[:, (0, 1, 2)]))\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# 创建 StandardScaler 实例\n",
    "scaler = StandardScaler()\n",
    "# 假设 X 是输入特征数据\n",
    "# 在训练集上拟合（计算均值和方差），并对数据进行标准化\n",
    "nn = 700\n",
    "X_train_scaled = scaler.fit_transform(params[:nn])\n",
    "# 在测试集上使用相同的标准化器进行标准化\n",
    "X_test_scaled = scaler.transform(params[nn:])\n",
    "\n",
    "\n",
    "num, _ = params.shape\n",
    "train_x = torch.from_numpy(X_train_scaled).to(torch.float)\n",
    "\n",
    "train_y_pidr1 = torch.from_numpy(edpResults[:nn, 0]).to(torch.float)\n",
    "train_y_pidr2 = torch.from_numpy(edpResults[:nn, 1]).to(torch.float)\n",
    "train_y_pidr3 = torch.from_numpy(edpResults[:nn, 2]).to(torch.float)\n",
    "train_y_pfa1 = torch.from_numpy(edpResults[:nn, 3]).to(torch.float)\n",
    "train_y_pfa2 = torch.from_numpy(edpResults[:nn, 4]).to(torch.float)\n",
    "train_y_pfa3 = torch.from_numpy(edpResults[:nn, 5]).to(torch.float)\n",
    "train_y_pfa4 = torch.from_numpy(edpResults[:nn, 6]).to(torch.float)\n",
    "\n",
    "\n",
    "state_dict_pidr1 = torch.load('pidr1_model_state.pth')\n",
    "state_dict_pidr2 = torch.load('pidr2_model_state.pth')\n",
    "state_dict_pidr3 = torch.load('pidr3_model_state.pth')\n",
    "state_dict_pfa1 = torch.load('pfa1_model_state.pth')\n",
    "state_dict_pfa2 = torch.load('pfa2_model_state.pth')\n",
    "state_dict_pfa3 = torch.load('pfa3_model_state.pth')\n",
    "state_dict_pfa4 = torch.load('pfa4_model_state.pth')\n",
    "state_dict_ridr = torch.load('ridr_model_state.pth')\n",
    "\n",
    "# We will use the simplest form of GP model, exact inference\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, dims):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=dims))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# initialize likelihood and model\n",
    "likelihood_pidr1 = gpytorch.likelihoods.GaussianLikelihood()\n",
    "likelihood_pidr2 = gpytorch.likelihoods.GaussianLikelihood()\n",
    "likelihood_pidr3 = gpytorch.likelihoods.GaussianLikelihood()\n",
    "likelihood_pfa1 = gpytorch.likelihoods.GaussianLikelihood()\n",
    "likelihood_pfa2 = gpytorch.likelihoods.GaussianLikelihood()\n",
    "likelihood_pfa3 = gpytorch.likelihoods.GaussianLikelihood()\n",
    "likelihood_pfa4 = gpytorch.likelihoods.GaussianLikelihood()\n",
    "\n",
    "\n",
    "model_pidr1 = ExactGPModel(train_x, train_y_pidr1, likelihood_pidr1, 9)\n",
    "model_pidr2 = ExactGPModel(train_x, train_y_pidr2, likelihood_pidr2, 9)\n",
    "model_pidr3 = ExactGPModel(train_x, train_y_pidr3, likelihood_pidr3, 9)\n",
    "model_pfa1 = ExactGPModel(train_x, train_y_pfa1, likelihood_pfa1, 9)\n",
    "model_pfa2 = ExactGPModel(train_x, train_y_pfa2, likelihood_pfa2, 9)\n",
    "model_pfa3 = ExactGPModel(train_x, train_y_pfa3, likelihood_pfa3, 9)\n",
    "model_pfa4 = ExactGPModel(train_x, train_y_pfa4, likelihood_pfa4, 9)\n",
    "\n",
    "model_pidr1.load_state_dict(state_dict_pidr1)\n",
    "model_pidr2.load_state_dict(state_dict_pidr2)\n",
    "model_pidr3.load_state_dict(state_dict_pidr3)\n",
    "model_pfa1.load_state_dict(state_dict_pfa1)\n",
    "model_pfa2.load_state_dict(state_dict_pfa2)\n",
    "model_pfa3.load_state_dict(state_dict_pfa3)\n",
    "model_pfa4.load_state_dict(state_dict_pfa4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get into evaluation (predictive posterior) mode\n",
    "# pidr1\n",
    "model_pidr1.eval()\n",
    "likelihood_pidr1.eval()\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.from_numpy(X_test_scaled).to(torch.float)\n",
    "    observed_pred_test_pidr1 = likelihood_pidr1(model_pidr1(test_x))\n",
    "# pidr2\n",
    "model_pidr2.eval()\n",
    "likelihood_pidr2.eval()\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.from_numpy(X_test_scaled).to(torch.float)\n",
    "    observed_pred_test_pidr2 = likelihood_pidr2(model_pidr2(test_x))\n",
    "# pidr3\n",
    "model_pidr3.eval()\n",
    "likelihood_pidr3.eval()\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.from_numpy(X_test_scaled).to(torch.float)\n",
    "    observed_pred_test_pidr3 = likelihood_pidr3(model_pidr3(test_x))\n",
    "# pfa1\n",
    "model_pfa1.eval()\n",
    "likelihood_pfa1.eval()\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.from_numpy(X_test_scaled).to(torch.float)\n",
    "    observed_pred_test_pfa1 = likelihood_pfa1(model_pfa1(test_x))\n",
    "# pfa2\n",
    "model_pfa2.eval()\n",
    "likelihood_pfa2.eval()\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.from_numpy(X_test_scaled).to(torch.float)\n",
    "    observed_pred_test_pfa2 = likelihood_pfa2(model_pfa2(test_x))\n",
    "# pfa3\n",
    "model_pfa3.eval()\n",
    "likelihood_pfa3.eval()\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.from_numpy(X_test_scaled).to(torch.float)\n",
    "    observed_pred_test_pfa3 = likelihood_pfa3(model_pfa3(test_x))\n",
    "# pfa4\n",
    "model_pfa4.eval()\n",
    "likelihood_pfa4.eval()\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.from_numpy(X_test_scaled).to(torch.float)\n",
    "    observed_pred_test_pfa4 = likelihood_pfa4(model_pfa4(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ridr\n",
    "X_train_ridr_scaled = scaler.fit_transform(params_ridr[:nn])\n",
    "params_ridr[nn:, 9] = observed_pred_test_pidr1.mean.numpy()\n",
    "params_ridr[nn:, 10] = observed_pred_test_pidr2.mean.numpy()\n",
    "params_ridr[nn:, 11] = observed_pred_test_pidr3.mean.numpy()\n",
    "X_test_ridr_scaled = scaler.transform(params_ridr[nn:])\n",
    "train_x_ridr = torch.from_numpy(X_train_ridr_scaled).to(torch.float)\n",
    "train_y_ridr = torch.from_numpy(edpResults[:nn, 7]).to(torch.float)\n",
    "likelihood_ridr = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model_ridr = ExactGPModel(train_x_ridr, train_y_ridr, likelihood_ridr, 12)\n",
    "model_ridr.load_state_dict(state_dict_ridr)\n",
    "\n",
    "model_ridr.eval()\n",
    "likelihood_ridr.eval()\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.from_numpy(X_test_ridr_scaled).to(torch.float)\n",
    "    observed_pred_test_ridr = likelihood_ridr(model_ridr(test_x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9970489544030391\n",
      "0.9964075167605579\n",
      "0.9926798372463452\n",
      "0.9999686821234088\n",
      "0.9881371401413763\n",
      "0.9790047546513722\n",
      "0.9849476609562127\n",
      "0.9799089692869671\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r_squared_sklearn_test = r2_score(np.exp(edpResults[nn:, 0]), np.exp(observed_pred_test_pidr1.mean.numpy()))\n",
    "print(r_squared_sklearn_test)\n",
    "r_squared_sklearn_test = r2_score(np.exp(edpResults[nn:, 1]), np.exp(observed_pred_test_pidr2.mean.numpy()))\n",
    "print(r_squared_sklearn_test)\n",
    "r_squared_sklearn_test = r2_score(np.exp(edpResults[nn:, 2]), np.exp(observed_pred_test_pidr3.mean.numpy()))\n",
    "print(r_squared_sklearn_test)\n",
    "r_squared_sklearn_test = r2_score(np.exp(edpResults[nn:, 3]), np.exp(observed_pred_test_pfa1.mean.numpy()))\n",
    "print(r_squared_sklearn_test)\n",
    "r_squared_sklearn_test = r2_score(np.exp(edpResults[nn:, 4]), np.exp(observed_pred_test_pfa2.mean.numpy()))\n",
    "print(r_squared_sklearn_test)\n",
    "r_squared_sklearn_test = r2_score(np.exp(edpResults[nn:, 5]), np.exp(observed_pred_test_pfa3.mean.numpy()))\n",
    "print(r_squared_sklearn_test)\n",
    "r_squared_sklearn_test = r2_score(np.exp(edpResults[nn:, 6]), np.exp(observed_pred_test_pfa4.mean.numpy()))\n",
    "print(r_squared_sklearn_test)\n",
    "r_squared_sklearn_test = r2_score(np.exp(edpResults[nn:, 7]), np.exp(observed_pred_test_ridr.mean.numpy()))\n",
    "print(r_squared_sklearn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "from GPRmodel import GPRmodel\n",
    "\n",
    "# 导入数据\n",
    "params = np.loadtxt('0915params_2475year.txt')\n",
    "edpResults = np.loadtxt('0915edpResult_2475year.txt')\n",
    "\n",
    "params = params[:, (1, 2, 3, 4, 5, 6, 7, 8, 10)]\n",
    "edpResults = np.log(edpResults)\n",
    "\n",
    "X_predict = params[700:, :]\n",
    "Y_predict = GPRmodel(X_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9970489544030391\n",
      "0.9964075167605579\n",
      "0.9926798372463452\n",
      "0.9999686821234088\n",
      "0.9881371401413763\n",
      "0.9790047546513722\n",
      "0.9849476609562127\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "for n in range(7):\n",
    "    r_squared_sklearn_test = r2_score(np.exp(edpResults[700:, n]), Y_predict[:, n])\n",
    "    print(r_squared_sklearn_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
