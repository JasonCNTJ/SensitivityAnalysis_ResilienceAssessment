{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入合适的库\n",
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "import pyro\n",
    "from pyro.infer.mcmc import NUTS, MCMC, HMC\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入数据\n",
    "params = np.loadtxt('0823paramsnp.txt')\n",
    "edpResults = np.loadtxt('0823edpResult.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查params数据是否正确 [T1, mb, kesi, PGA, PGV, PGD, Sd, Sv, Sa]\n",
    "print(params.shape)\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查edpResults数据是否正确 [IDR1_MAX, IDR2_MAX, IDR3_MAX, amax0, amax1, amax2, amax3, residual_idr]\n",
    "print(edpResults.shape)\n",
    "edpResults = np.log(edpResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# 创建 StandardScaler 实例\n",
    "scaler = StandardScaler()\n",
    "# 假设 X 是输入特征数据\n",
    "# 在训练集上拟合（计算均值和方差），并对数据进行标准化\n",
    "X_train_scaled = scaler.fit_transform(params[:1600])\n",
    "# 在测试集上使用相同的标准化器进行标准化\n",
    "X_test_scaled = scaler.transform(params[1600:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据抓换成torch格式\n",
    "n = 4\n",
    "train_x = torch.from_numpy(X_train_scaled).to(torch.float)\n",
    "train_y = torch.from_numpy(edpResults[:1600, n]).to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the simplest form of GP model, exact inference\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(train_x, train_y, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "import os\n",
    "smoke_test = ('CI' in os.environ)\n",
    "num_samples = 2 if smoke_test else 100\n",
    "warmup_steps = 2 if smoke_test else 100\n",
    "\n",
    "\n",
    "from gpytorch.priors import LogNormalPrior, NormalPrior, UniformPrior\n",
    "# Use a positive constraint instead of usual GreaterThan(1e-4) so that LogNormal has support over full range.\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood(noise_constraint=gpytorch.constraints.Positive())\n",
    "model = ExactGPModel(train_x, train_y, likelihood)\n",
    "\n",
    "model.mean_module.register_prior(\"mean_prior\", UniformPrior(-1, 1), \"constant\")\n",
    "model.covar_module.base_kernel.register_prior(\"lengthscale_prior\", UniformPrior(0.01, 0.5), \"lengthscale\")\n",
    "model.covar_module.register_prior(\"outputscale_prior\", UniformPrior(1, 2), \"outputscale\")\n",
    "likelihood.register_prior(\"noise_prior\", UniformPrior(0.01, 0.5), \"noise\")\n",
    "\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "def pyro_model(x, y):\n",
    "    with gpytorch.settings.fast_computations(False, False, False):\n",
    "        sampled_model = model.pyro_sample_from_prior()\n",
    "        output = sampled_model.likelihood(sampled_model(x))\n",
    "        pyro.sample(\"obs\", output, obs=y)\n",
    "    return y\n",
    "\n",
    "nuts_kernel = NUTS(pyro_model)\n",
    "mcmc_run = MCMC(nuts_kernel, num_samples=num_samples, warmup_steps=warmup_steps, disable_progbar=smoke_test)\n",
    "mcmc_run.run(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pyro_load_from_samples(mcmc_run.get_samples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_x = torch.from_numpy(X_test_scaled).to(torch.float)\n",
    "output = model(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get into evaluation (predictive posterior) mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.from_numpy(X_test_scaled).to(torch.float)\n",
    "    observed_pred_test = likelihood(model(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r_squared_sklearn_test = r2_score(edpResults[1600:, n], observed_pred_test.mean.numpy())\n",
    "print(r_squared_sklearn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get into evaluation (predictive posterior) mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    # test_x = torch.from_numpy(params[1600:]).to(torch.float)\n",
    "    observed_pred_train = likelihood(model(train_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r_squared_sklearn_train = r2_score(edpResults[:1600, n], observed_pred_train.mean.numpy())\n",
    "print(r_squared_sklearn_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 生成示例数据（模拟预测值和观测值）\n",
    "np.random.seed(0)\n",
    "# observed_values = edpResults[:1600, 0]\n",
    "# predicted_values = observed_pred_train.mean.numpy()\n",
    "observed_values = edpResults[1600:, n]\n",
    "predicted_values = observed_pred_test.mean.numpy()\n",
    "# 绘制散点图和对角线\n",
    "a = 1\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(predicted_values, observed_values, color='blue', label='Data')\n",
    "plt.plot([0, a], [0, a], color='red', linestyle='--', label='Diagonal Line')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Observed Values')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "# plt.title('QQ Plot with Diagonal Line')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 生成示例数据（模拟预测值和观测值）\n",
    "np.random.seed(0)\n",
    "# observed_values = edpResults[:1600, 0]\n",
    "# predicted_values = observed_pred_train.mean.numpy()\n",
    "observed_values = edpResults[1600:, n]\n",
    "predicted_values = observed_pred_test.mean.numpy()\n",
    "# 绘制散点图和对角线\n",
    "a = 0.02\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(predicted_values, observed_values, color='blue', label='Data')\n",
    "plt.plot([0, a], [0, a], color='red', linestyle='--', label='Diagonal Line')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Observed Values')\n",
    "plt.xlim([0, 0.02])\n",
    "plt.ylim([0, 0.02])\n",
    "# plt.title('QQ Plot with Diagonal Line')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
