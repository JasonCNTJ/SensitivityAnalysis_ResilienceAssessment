{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入合适的库\n",
    "import numpy as np\n",
    "import torch\n",
    "import gpytorch\n",
    "import matplotlib.pyplot as plt\n",
    "from GPRmodel import GPRmodel\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入数据\n",
    "params = np.loadtxt('0915params_2475year.txt')\n",
    "edpResults = np.loadtxt('0915edpResult_2475year.txt')\n",
    "\n",
    "params = params[:, (1, 2, 3, 4, 5, 6, 7, 8, 10)]\n",
    "\n",
    "X_predict = params\n",
    "Y_predict = GPRmodel(X_predict)\n",
    "\n",
    "# X_predict = np.hstack((X_predict, np.exp(Y_predict[:, :3])))\n",
    "# params = X_predict\n",
    "np.savetxt('param_pred.txt', Y_predict[:700, (0, 1, 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1040, 12)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.07001820e+00, 3.41753683e-02, 1.44143855e+01, ...,\n",
       "        1.68370698e-02, 1.88458506e-02, 1.14213759e-02],\n",
       "       [9.39678177e-01, 3.74978086e-02, 1.14275351e+01, ...,\n",
       "        1.82970632e-02, 1.53113538e-02, 8.24177358e-03],\n",
       "       [1.11246337e+00, 2.83235782e-02, 1.86685135e+01, ...,\n",
       "        3.04235108e-02, 2.28708852e-02, 1.16930455e-02],\n",
       "       ...,\n",
       "       [1.11903868e+00, 3.38242508e-02, 1.41571810e+01, ...,\n",
       "        1.38012758e-02, 1.42483804e-02, 8.99087265e-03],\n",
       "       [1.07694660e+00, 4.36945601e-02, 1.03387621e+01, ...,\n",
       "        1.77634731e-02, 1.71621032e-02, 9.16692521e-03],\n",
       "       [9.43091938e-01, 4.01084932e-02, 1.16677655e+01, ...,\n",
       "        2.02503521e-02, 1.81694329e-02, 8.97810515e-03]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 检查params数据是否正确 [T1, mb, kesi, PGA, PGV, PGD, Sd, Sv, Sa]9 theta1: Ia; theta2: D_5-95; theta3: t_mid; theta4: w_mid; theta5: w'; theta6: kesi_f 6 MRVF\n",
    "#                        0   1    2     3    4    5   6   7   8            9             10             11              12           13            14   \n",
    "print(params.shape)  \n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1040, 8)\n"
     ]
    }
   ],
   "source": [
    "# 检查edpResults数据是否正确 [IDR1_MAX, IDR2_MAX, IDR3_MAX, amax0, amax1, amax2, amax3, residual_idr]\n",
    "print(edpResults.shape)\n",
    "edpResults = np.log(edpResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# 创建 StandardScaler 实例\n",
    "scaler = StandardScaler()\n",
    "# 假设 X 是输入特征数据\n",
    "# 在训练集上拟合（计算均值和方差），并对数据进行标准化\n",
    "nn = 700\n",
    "X_train_scaled = scaler.fit_transform(params[:nn])\n",
    "# 在测试集上使用相同的标准化器进行标准化\n",
    "X_test_scaled = scaler.transform(params[nn:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据抓换成torch格式\n",
    "n = 7\n",
    "num, dims = params.shape\n",
    "train_x = torch.from_numpy(X_train_scaled).to(torch.float)\n",
    "train_y = torch.from_numpy(edpResults[:nn, n]).to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the simplest form of GP model, exact inference\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=dims))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(train_x, train_y, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/200\n",
      "tensor([[0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931, 0.6931,\n",
      "         0.6931, 0.6931, 0.6931]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 2/200\n",
      "tensor([[0.7444, 0.7444, 0.7444, 0.7444, 0.7444, 0.6931, 0.7444, 0.6931, 0.7444,\n",
      "         0.7444, 0.7444, 0.7444]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 3/200\n",
      "tensor([[0.7975, 0.7975, 0.7981, 0.7979, 0.7979, 0.6931, 0.7981, 0.6931, 0.7981,\n",
      "         0.7978, 0.7978, 0.7977]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 4/200\n",
      "tensor([[0.8519, 0.8519, 0.8541, 0.8533, 0.8534, 0.6931, 0.8539, 0.6931, 0.8540,\n",
      "         0.8528, 0.8528, 0.8527]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 5/200\n",
      "tensor([[0.9070, 0.9070, 0.9120, 0.9100, 0.9104, 0.6931, 0.9114, 0.6931, 0.9119,\n",
      "         0.9090, 0.9090, 0.9087]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 6/200\n",
      "tensor([[0.9622, 0.9621, 0.9713, 0.9674, 0.9683, 0.6931, 0.9702, 0.6931, 0.9714,\n",
      "         0.9659, 0.9658, 0.9653]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 7/200\n",
      "tensor([[1.0169, 1.0167, 1.0314, 1.0249, 1.0268, 0.6931, 1.0296, 0.6931, 1.0320,\n",
      "         1.0228, 1.0227, 1.0219]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 8/200\n",
      "tensor([[1.0707, 1.0704, 1.0918, 1.0821, 1.0852, 0.6931, 1.0891, 0.6931, 1.0933,\n",
      "         1.0794, 1.0792, 1.0781]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 9/200\n",
      "tensor([[1.1231, 1.1228, 1.1518, 1.1384, 1.1432, 0.6931, 1.1480, 0.6931, 1.1547,\n",
      "         1.1352, 1.1350, 1.1333]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 10/200\n",
      "tensor([[1.1739, 1.1736, 1.2111, 1.1936, 1.2003, 0.6931, 1.2061, 0.6931, 1.2158,\n",
      "         1.1898, 1.1895, 1.1872]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 11/200\n",
      "tensor([[1.2229, 1.2227, 1.2690, 1.2474, 1.2563, 0.6931, 1.2627, 0.6931, 1.2761,\n",
      "         1.2430, 1.2427, 1.2397]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 12/200\n",
      "tensor([[1.2699, 1.2698, 1.3254, 1.2997, 1.3109, 0.6931, 1.3178, 0.6931, 1.3354,\n",
      "         1.2945, 1.2942, 1.2903]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 13/200\n",
      "tensor([[1.3149, 1.3150, 1.3800, 1.3503, 1.3638, 0.6931, 1.3709, 0.6931, 1.3932,\n",
      "         1.3442, 1.3440, 1.3392]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 14/200\n",
      "tensor([[1.3578, 1.3582, 1.4325, 1.3992, 1.4150, 0.6931, 1.4220, 0.6931, 1.4493,\n",
      "         1.3919, 1.3919, 1.3860]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 15/200\n",
      "tensor([[1.3986, 1.3994, 1.4830, 1.4463, 1.4643, 0.6931, 1.4709, 0.6931, 1.5037,\n",
      "         1.4376, 1.4379, 1.4308]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 16/200\n",
      "tensor([[1.4373, 1.4386, 1.5311, 1.4915, 1.5116, 0.6931, 1.5175, 0.6931, 1.5560,\n",
      "         1.4812, 1.4819, 1.4736]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 17/200\n",
      "tensor([[1.4741, 1.4759, 1.5771, 1.5349, 1.5569, 0.6931, 1.5619, 0.6931, 1.6064,\n",
      "         1.5228, 1.5240, 1.5144]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 18/200\n",
      "tensor([[1.5088, 1.5113, 1.6208, 1.5764, 1.6001, 0.6931, 1.6040, 0.6931, 1.6546,\n",
      "         1.5622, 1.5642, 1.5531]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 19/200\n",
      "tensor([[1.5417, 1.5450, 1.6624, 1.6161, 1.6414, 0.6931, 1.6439, 0.6931, 1.7008,\n",
      "         1.5996, 1.6025, 1.5899]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 20/200\n",
      "tensor([[1.5728, 1.5770, 1.7017, 1.6541, 1.6807, 0.6931, 1.6816, 0.6931, 1.7448,\n",
      "         1.6351, 1.6390, 1.6248]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 21/200\n",
      "tensor([[1.6021, 1.6074, 1.7390, 1.6902, 1.7180, 0.6931, 1.7172, 0.6931, 1.7868,\n",
      "         1.6685, 1.6737, 1.6579]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 22/200\n",
      "tensor([[1.6298, 1.6363, 1.7743, 1.7248, 1.7534, 0.6931, 1.7507, 0.6931, 1.8268,\n",
      "         1.7001, 1.7066, 1.6892]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 23/200\n",
      "tensor([[1.6559, 1.6637, 1.8075, 1.7576, 1.7870, 0.6931, 1.7822, 0.6931, 1.8648,\n",
      "         1.7299, 1.7379, 1.7188]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 24/200\n",
      "tensor([[1.6805, 1.6898, 1.8389, 1.7889, 1.8187, 0.6931, 1.8117, 0.6931, 1.9009,\n",
      "         1.7579, 1.7676, 1.7468]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 25/200\n",
      "tensor([[1.7037, 1.7146, 1.8685, 1.8186, 1.8488, 0.6931, 1.8394, 0.6931, 1.9351,\n",
      "         1.7842, 1.7958, 1.7733]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 26/200\n",
      "tensor([[1.7256, 1.7382, 1.8963, 1.8468, 1.8771, 0.6931, 1.8653, 0.6931, 1.9676,\n",
      "         1.8089, 1.8225, 1.7984]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 27/200\n",
      "tensor([[1.7462, 1.7607, 1.9225, 1.8736, 1.9038, 0.6931, 1.8895, 0.6931, 1.9983,\n",
      "         1.8321, 1.8478, 1.8220]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 28/200\n",
      "tensor([[1.7656, 1.7822, 1.9470, 1.8990, 1.9290, 0.6931, 1.9120, 0.6931, 2.0273,\n",
      "         1.8537, 1.8718, 1.8443]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 29/200\n",
      "tensor([[1.7839, 1.8027, 1.9700, 1.9230, 1.9527, 0.6931, 1.9328, 0.6931, 2.0547,\n",
      "         1.8739, 1.8945, 1.8654]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 30/200\n",
      "tensor([[1.8011, 1.8223, 1.9916, 1.9457, 1.9749, 0.6931, 1.9522, 0.6931, 2.0806,\n",
      "         1.8926, 1.9160, 1.8852]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 31/200\n",
      "tensor([[1.8173, 1.8411, 2.0117, 1.9671, 1.9956, 0.6931, 1.9700, 0.6931, 2.1049,\n",
      "         1.9100, 1.9362, 1.9039]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 32/200\n",
      "tensor([[1.8325, 1.8591, 2.0304, 1.9872, 2.0150, 0.6931, 1.9864, 0.6931, 2.1278,\n",
      "         1.9261, 1.9553, 1.9215]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 33/200\n",
      "tensor([[1.8467, 1.8764, 2.0477, 2.0061, 2.0330, 0.6931, 2.0014, 0.6931, 2.1493,\n",
      "         1.9408, 1.9733, 1.9381]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 34/200\n",
      "tensor([[1.8600, 1.8930, 2.0638, 2.0237, 2.0497, 0.6931, 2.0149, 0.6931, 2.1694,\n",
      "         1.9543, 1.9902, 1.9535]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 35/200\n",
      "tensor([[1.8724, 1.9090, 2.0786, 2.0401, 2.0651, 0.6931, 2.0271, 0.6931, 2.1881,\n",
      "         1.9666, 2.0061, 1.9680]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 36/200\n",
      "tensor([[1.8840, 1.9245, 2.0920, 2.0553, 2.0792, 0.6931, 2.0379, 0.6931, 2.2055,\n",
      "         1.9776, 2.0209, 1.9815]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 37/200\n",
      "tensor([[1.8947, 1.9394, 2.1043, 2.0693, 2.0920, 0.6931, 2.0474, 0.6931, 2.2216,\n",
      "         1.9874, 2.0346, 1.9941]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 38/200\n",
      "tensor([[1.9045, 1.9537, 2.1152, 2.0820, 2.1035, 0.6931, 2.0556, 0.6931, 2.2364,\n",
      "         1.9959, 2.0473, 2.0056]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 39/200\n",
      "tensor([[1.9135, 1.9676, 2.1250, 2.0934, 2.1137, 0.6931, 2.0624, 0.6931, 2.2499,\n",
      "         2.0032, 2.0590, 2.0163]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 40/200\n",
      "tensor([[1.9217, 1.9811, 2.1334, 2.1035, 2.1225, 0.6931, 2.0678, 0.6931, 2.2621,\n",
      "         2.0092, 2.0697, 2.0259]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 41/200\n",
      "tensor([[1.9290, 1.9941, 2.1406, 2.1123, 2.1301, 0.6931, 2.0720, 0.6931, 2.2731,\n",
      "         2.0140, 2.0792, 2.0346]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 42/200\n",
      "tensor([[1.9354, 2.0067, 2.1466, 2.1198, 2.1364, 0.6931, 2.0747, 0.6931, 2.2828,\n",
      "         2.0175, 2.0877, 2.0423]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 43/200\n",
      "tensor([[1.9409, 2.0189, 2.1512, 2.1259, 2.1413, 0.6931, 2.0761, 0.6931, 2.2912,\n",
      "         2.0197, 2.0951, 2.0490]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 44/200\n",
      "tensor([[1.9456, 2.0306, 2.1546, 2.1305, 2.1448, 0.6931, 2.0761, 0.6931, 2.2984,\n",
      "         2.0207, 2.1014, 2.0548]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 45/200\n",
      "tensor([[1.9494, 2.0420, 2.1567, 2.1338, 2.1470, 0.6931, 2.0747, 0.6931, 2.3043,\n",
      "         2.0203, 2.1066, 2.0595]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 46/200\n",
      "tensor([[1.9522, 2.0531, 2.1574, 2.1356, 2.1479, 0.6931, 2.0720, 0.6931, 2.3090,\n",
      "         2.0186, 2.1106, 2.0631]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 47/200\n",
      "tensor([[1.9542, 2.0637, 2.1569, 2.1360, 2.1473, 0.6931, 2.0679, 0.6931, 2.3125,\n",
      "         2.0156, 2.1135, 2.0658]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 48/200\n",
      "tensor([[1.9552, 2.0740, 2.1551, 2.1349, 2.1455, 0.6931, 2.0624, 0.6931, 2.3147,\n",
      "         2.0114, 2.1153, 2.0674]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 49/200\n",
      "tensor([[1.9554, 2.0840, 2.1520, 2.1323, 2.1423, 0.6931, 2.0555, 0.6931, 2.3158,\n",
      "         2.0058, 2.1159, 2.0680]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 50/200\n",
      "tensor([[1.9546, 2.0936, 2.1477, 2.1284, 2.1379, 0.6931, 2.0474, 0.6931, 2.3157,\n",
      "         1.9990, 2.1153, 2.0675]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 51/200\n",
      "tensor([[1.9530, 2.1028, 2.1422, 2.1231, 2.1322, 0.6931, 2.0379, 0.6931, 2.3146,\n",
      "         1.9911, 2.1137, 2.0661]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 52/200\n",
      "tensor([[1.9505, 2.1118, 2.1355, 2.1165, 2.1253, 0.6931, 2.0273, 0.6931, 2.3124,\n",
      "         1.9820, 2.1110, 2.0638]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 53/200\n",
      "tensor([[1.9473, 2.1204, 2.1278, 2.1086, 2.1174, 0.6931, 2.0155, 0.6931, 2.3093,\n",
      "         1.9718, 2.1073, 2.0605]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 54/200\n",
      "tensor([[1.9432, 2.1287, 2.1190, 2.0995, 2.1084, 0.6931, 2.0026, 0.6931, 2.3052,\n",
      "         1.9606, 2.1027, 2.0564]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 55/200\n",
      "tensor([[1.9385, 2.1368, 2.1094, 2.0893, 2.0985, 0.6931, 1.9888, 0.6931, 2.3004,\n",
      "         1.9485, 2.0972, 2.0516]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 56/200\n",
      "tensor([[1.9331, 2.1446, 2.0988, 2.0782, 2.0877, 0.6931, 1.9740, 0.6931, 2.2949,\n",
      "         1.9355, 2.0909, 2.0460]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 57/200\n",
      "tensor([[1.9271, 2.1522, 2.0875, 2.0661, 2.0762, 0.6931, 1.9584, 0.6931, 2.2887,\n",
      "         1.9219, 2.0838, 2.0397]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 58/200\n",
      "tensor([[1.9206, 2.1596, 2.0755, 2.0533, 2.0640, 0.6931, 1.9421, 0.6931, 2.2819,\n",
      "         1.9076, 2.0761, 2.0330]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 59/200\n",
      "tensor([[1.9137, 2.1668, 2.0630, 2.0398, 2.0513, 0.6931, 1.9252, 0.6931, 2.2748,\n",
      "         1.8928, 2.0679, 2.0257]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 60/200\n",
      "tensor([[1.9063, 2.1738, 2.0500, 2.0257, 2.0381, 0.6931, 1.9078, 0.6931, 2.2672,\n",
      "         1.8776, 2.0592, 2.0180]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 61/200\n",
      "tensor([[1.8987, 2.1807, 2.0366, 2.0111, 2.0246, 0.6931, 1.8899, 0.6931, 2.2594,\n",
      "         1.8621, 2.0501, 2.0101]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 62/200\n",
      "tensor([[1.8907, 2.1875, 2.0228, 1.9962, 2.0108, 0.6931, 1.8717, 0.6931, 2.2514,\n",
      "         1.8463, 2.0408, 2.0019]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 63/200\n",
      "tensor([[1.8826, 2.1942, 2.0089, 1.9809, 1.9968, 0.6931, 1.8533, 0.6931, 2.2433,\n",
      "         1.8304, 2.0312, 1.9935]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 64/200\n",
      "tensor([[1.8744, 2.2008, 1.9948, 1.9655, 1.9828, 0.6931, 1.8347, 0.6931, 2.2351,\n",
      "         1.8145, 2.0215, 1.9850]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 65/200\n",
      "tensor([[1.8660, 2.2074, 1.9806, 1.9500, 1.9687, 0.6931, 1.8160, 0.6931, 2.2269,\n",
      "         1.7986, 2.0117, 1.9765]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 66/200\n",
      "tensor([[1.8576, 2.2140, 1.9664, 1.9344, 1.9547, 0.6931, 1.7973, 0.6931, 2.2188,\n",
      "         1.7828, 2.0019, 1.9680]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 67/200\n",
      "tensor([[1.8492, 2.2205, 1.9522, 1.9188, 1.9408, 0.6931, 1.7787, 0.6931, 2.2108,\n",
      "         1.7672, 1.9922, 1.9596]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 68/200\n",
      "tensor([[1.8408, 2.2270, 1.9381, 1.9033, 1.9270, 0.6931, 1.7601, 0.6931, 2.2030,\n",
      "         1.7518, 1.9825, 1.9513]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 69/200\n",
      "tensor([[1.8325, 2.2335, 1.9242, 1.8879, 1.9134, 0.6931, 1.7416, 0.6931, 2.1953,\n",
      "         1.7367, 1.9729, 1.9431]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 70/200\n",
      "tensor([[1.8243, 2.2400, 1.9104, 1.8726, 1.9001, 0.6931, 1.7234, 0.6931, 2.1879,\n",
      "         1.7218, 1.9635, 1.9350]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 71/200\n",
      "tensor([[1.8161, 2.2466, 1.8968, 1.8576, 1.8870, 0.6931, 1.7053, 0.6931, 2.1808,\n",
      "         1.7074, 1.9542, 1.9272]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 72/200\n",
      "tensor([[1.8081, 2.2531, 1.8834, 1.8427, 1.8742, 0.6931, 1.6874, 0.6931, 2.1739,\n",
      "         1.6932, 1.9452, 1.9196]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 73/200\n",
      "tensor([[1.8002, 2.2597, 1.8702, 1.8281, 1.8618, 0.6931, 1.6698, 0.6931, 2.1673,\n",
      "         1.6795, 1.9363, 1.9122]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 74/200\n",
      "tensor([[1.7925, 2.2663, 1.8573, 1.8137, 1.8496, 0.6931, 1.6524, 0.6931, 2.1610,\n",
      "         1.6662, 1.9276, 1.9051]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 75/200\n",
      "tensor([[1.7849, 2.2729, 1.8446, 1.7995, 1.8378, 0.6931, 1.6353, 0.6931, 2.1549,\n",
      "         1.6533, 1.9191, 1.8981]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 76/200\n",
      "tensor([[1.7774, 2.2796, 1.8322, 1.7856, 1.8262, 0.6931, 1.6185, 0.6931, 2.1492,\n",
      "         1.6408, 1.9109, 1.8915]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 77/200\n",
      "tensor([[1.7700, 2.2863, 1.8201, 1.7719, 1.8151, 0.6931, 1.6019, 0.6931, 2.1438,\n",
      "         1.6287, 1.9028, 1.8850]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 78/200\n",
      "tensor([[1.7628, 2.2930, 1.8082, 1.7585, 1.8042, 0.6931, 1.5856, 0.6931, 2.1387,\n",
      "         1.6170, 1.8949, 1.8788]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 79/200\n",
      "tensor([[1.7556, 2.2997, 1.7965, 1.7453, 1.7937, 0.6931, 1.5695, 0.6931, 2.1338,\n",
      "         1.6057, 1.8872, 1.8728]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 80/200\n",
      "tensor([[1.7486, 2.3064, 1.7851, 1.7323, 1.7835, 0.6931, 1.5537, 0.6931, 2.1293,\n",
      "         1.5948, 1.8796, 1.8670]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 81/200\n",
      "tensor([[1.7417, 2.3132, 1.7740, 1.7195, 1.7736, 0.6931, 1.5381, 0.6931, 2.1250,\n",
      "         1.5844, 1.8722, 1.8614]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 82/200\n",
      "tensor([[1.7348, 2.3200, 1.7631, 1.7070, 1.7640, 0.6931, 1.5227, 0.6931, 2.1209,\n",
      "         1.5742, 1.8650, 1.8560]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 83/200\n",
      "tensor([[1.7280, 2.3267, 1.7525, 1.6946, 1.7547, 0.6931, 1.5076, 0.6931, 2.1171,\n",
      "         1.5645, 1.8578, 1.8508]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 84/200\n",
      "tensor([[1.7212, 2.3335, 1.7421, 1.6824, 1.7457, 0.6931, 1.4926, 0.6931, 2.1136,\n",
      "         1.5551, 1.8507, 1.8458]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 85/200\n",
      "tensor([[1.7145, 2.3402, 1.7319, 1.6704, 1.7369, 0.6931, 1.4779, 0.6931, 2.1103,\n",
      "         1.5461, 1.8437, 1.8409]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 86/200\n",
      "tensor([[1.7078, 2.3470, 1.7220, 1.6586, 1.7284, 0.6931, 1.4633, 0.6931, 2.1072,\n",
      "         1.5373, 1.8368, 1.8362]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 87/200\n",
      "tensor([[1.7011, 2.3537, 1.7122, 1.6469, 1.7202, 0.6931, 1.4490, 0.6931, 2.1043,\n",
      "         1.5289, 1.8299, 1.8316]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 88/200\n",
      "tensor([[1.6943, 2.3603, 1.7027, 1.6353, 1.7122, 0.6931, 1.4348, 0.6931, 2.1016,\n",
      "         1.5208, 1.8231, 1.8272]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 89/200\n",
      "tensor([[1.6876, 2.3670, 1.6934, 1.6239, 1.7045, 0.6931, 1.4207, 0.6931, 2.0990,\n",
      "         1.5130, 1.8163, 1.8228]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 90/200\n",
      "tensor([[1.6808, 2.3736, 1.6843, 1.6127, 1.6970, 0.6931, 1.4069, 0.6931, 2.0967,\n",
      "         1.5054, 1.8095, 1.8186]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 91/200\n",
      "tensor([[1.6740, 2.3801, 1.6754, 1.6015, 1.6898, 0.6931, 1.3931, 0.6931, 2.0946,\n",
      "         1.4981, 1.8027, 1.8145]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 92/200\n",
      "tensor([[1.6671, 2.3867, 1.6667, 1.5905, 1.6827, 0.6931, 1.3796, 0.6931, 2.0926,\n",
      "         1.4911, 1.7958, 1.8105]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 93/200\n",
      "tensor([[1.6602, 2.3931, 1.6582, 1.5796, 1.6759, 0.6931, 1.3662, 0.6931, 2.0907,\n",
      "         1.4843, 1.7890, 1.8065]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 94/200\n",
      "tensor([[1.6532, 2.3995, 1.6500, 1.5688, 1.6693, 0.6931, 1.3529, 0.6931, 2.0890,\n",
      "         1.4778, 1.7822, 1.8027]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 95/200\n",
      "tensor([[1.6461, 2.4059, 1.6420, 1.5582, 1.6629, 0.6931, 1.3398, 0.6931, 2.0875,\n",
      "         1.4715, 1.7753, 1.7990]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 96/200\n",
      "tensor([[1.6390, 2.4122, 1.6341, 1.5477, 1.6568, 0.6931, 1.3269, 0.6931, 2.0861,\n",
      "         1.4655, 1.7684, 1.7953]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 97/200\n",
      "tensor([[1.6318, 2.4184, 1.6265, 1.5373, 1.6508, 0.6931, 1.3141, 0.6931, 2.0849,\n",
      "         1.4597, 1.7615, 1.7918]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 98/200\n",
      "tensor([[1.6246, 2.4246, 1.6192, 1.5271, 1.6451, 0.6931, 1.3014, 0.6931, 2.0838,\n",
      "         1.4542, 1.7546, 1.7883]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 99/200\n",
      "tensor([[1.6172, 2.4307, 1.6121, 1.5170, 1.6395, 0.6931, 1.2890, 0.6931, 2.0829,\n",
      "         1.4489, 1.7477, 1.7850]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 100/200\n",
      "tensor([[1.6098, 2.4367, 1.6052, 1.5070, 1.6342, 0.6931, 1.2767, 0.6931, 2.0821,\n",
      "         1.4438, 1.7408, 1.7818]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 101/200\n",
      "tensor([[1.6024, 2.4427, 1.5985, 1.4972, 1.6291, 0.6931, 1.2646, 0.6931, 2.0814,\n",
      "         1.4390, 1.7338, 1.7787]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 102/200\n",
      "tensor([[1.5949, 2.4487, 1.5921, 1.4876, 1.6242, 0.6931, 1.2527, 0.6931, 2.0809,\n",
      "         1.4345, 1.7270, 1.7757]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 103/200\n",
      "tensor([[1.5874, 2.4545, 1.5860, 1.4781, 1.6194, 0.6931, 1.2410, 0.6931, 2.0805,\n",
      "         1.4302, 1.7201, 1.7728]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 104/200\n",
      "tensor([[1.5799, 2.4604, 1.5801, 1.4688, 1.6150, 0.6931, 1.2295, 0.6931, 2.0803,\n",
      "         1.4261, 1.7133, 1.7701]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 105/200\n",
      "tensor([[1.5723, 2.4662, 1.5745, 1.4596, 1.6107, 0.6931, 1.2182, 0.6931, 2.0802,\n",
      "         1.4224, 1.7065, 1.7675]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 106/200\n",
      "tensor([[1.5647, 2.4719, 1.5691, 1.4506, 1.6066, 0.6931, 1.2071, 0.6931, 2.0803,\n",
      "         1.4188, 1.6998, 1.7651]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 107/200\n",
      "tensor([[1.5572, 2.4776, 1.5641, 1.4419, 1.6027, 0.6931, 1.1963, 0.6931, 2.0805,\n",
      "         1.4156, 1.6932, 1.7628]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 108/200\n",
      "tensor([[1.5496, 2.4833, 1.5592, 1.4333, 1.5990, 0.6931, 1.1856, 0.6931, 2.0808,\n",
      "         1.4126, 1.6867, 1.7607]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 109/200\n",
      "tensor([[1.5421, 2.4889, 1.5547, 1.4248, 1.5955, 0.6931, 1.1752, 0.6931, 2.0813,\n",
      "         1.4099, 1.6802, 1.7588]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 110/200\n",
      "tensor([[1.5345, 2.4945, 1.5504, 1.4166, 1.5922, 0.6931, 1.1650, 0.6931, 2.0819,\n",
      "         1.4074, 1.6739, 1.7570]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 111/200\n",
      "tensor([[1.5271, 2.5000, 1.5464, 1.4085, 1.5891, 0.6931, 1.1550, 0.6931, 2.0826,\n",
      "         1.4052, 1.6676, 1.7555]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 112/200\n",
      "tensor([[1.5196, 2.5055, 1.5427, 1.4007, 1.5862, 0.6931, 1.1452, 0.6931, 2.0835,\n",
      "         1.4033, 1.6615, 1.7541]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 113/200\n",
      "tensor([[1.5122, 2.5110, 1.5393, 1.3930, 1.5835, 0.6931, 1.1356, 0.6931, 2.0845,\n",
      "         1.4017, 1.6555, 1.7528]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 114/200\n",
      "tensor([[1.5048, 2.5165, 1.5361, 1.3855, 1.5809, 0.6931, 1.1263, 0.6931, 2.0857,\n",
      "         1.4002, 1.6497, 1.7518]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 115/200\n",
      "tensor([[1.4975, 2.5219, 1.5331, 1.3781, 1.5785, 0.6931, 1.1172, 0.6931, 2.0869,\n",
      "         1.3991, 1.6439, 1.7509]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 116/200\n",
      "tensor([[1.4902, 2.5273, 1.5305, 1.3710, 1.5762, 0.6931, 1.1083, 0.6931, 2.0883,\n",
      "         1.3982, 1.6383, 1.7502]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 117/200\n",
      "tensor([[1.4830, 2.5327, 1.5280, 1.3640, 1.5741, 0.6931, 1.0996, 0.6931, 2.0898,\n",
      "         1.3975, 1.6328, 1.7497]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 118/200\n",
      "tensor([[1.4758, 2.5381, 1.5258, 1.3571, 1.5722, 0.6931, 1.0910, 0.6931, 2.0914,\n",
      "         1.3970, 1.6275, 1.7494]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 119/200\n",
      "tensor([[1.4687, 2.5434, 1.5239, 1.3504, 1.5704, 0.6931, 1.0827, 0.6931, 2.0931,\n",
      "         1.3968, 1.6222, 1.7492]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 120/200\n",
      "tensor([[1.4617, 2.5487, 1.5222, 1.3439, 1.5686, 0.6931, 1.0746, 0.6931, 2.0949,\n",
      "         1.3968, 1.6172, 1.7493]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 121/200\n",
      "tensor([[1.4546, 2.5540, 1.5207, 1.3375, 1.5671, 0.6931, 1.0666, 0.6931, 2.0967,\n",
      "         1.3969, 1.6122, 1.7494]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 122/200\n",
      "tensor([[1.4477, 2.5592, 1.5194, 1.3312, 1.5656, 0.6931, 1.0588, 0.6931, 2.0987,\n",
      "         1.3973, 1.6073, 1.7498]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 123/200\n",
      "tensor([[1.4407, 2.5644, 1.5183, 1.3250, 1.5642, 0.6931, 1.0511, 0.6931, 2.1007,\n",
      "         1.3978, 1.6026, 1.7502]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 124/200\n",
      "tensor([[1.4338, 2.5696, 1.5174, 1.3190, 1.5629, 0.6931, 1.0436, 0.6931, 2.1029,\n",
      "         1.3985, 1.5980, 1.7509]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 125/200\n",
      "tensor([[1.4270, 2.5747, 1.5168, 1.3130, 1.5616, 0.6931, 1.0363, 0.6931, 2.1051,\n",
      "         1.3993, 1.5935, 1.7517]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 126/200\n",
      "tensor([[1.4201, 2.5799, 1.5163, 1.3072, 1.5605, 0.6931, 1.0291, 0.6931, 2.1073,\n",
      "         1.4003, 1.5891, 1.7526]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 127/200\n",
      "tensor([[1.4133, 2.5849, 1.5159, 1.3014, 1.5594, 0.6931, 1.0220, 0.6931, 2.1096,\n",
      "         1.4014, 1.5849, 1.7536]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 128/200\n",
      "tensor([[1.4066, 2.5899, 1.5158, 1.2957, 1.5583, 0.6931, 1.0150, 0.6931, 2.1120,\n",
      "         1.4026, 1.5807, 1.7548]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 129/200\n",
      "tensor([[1.3998, 2.5949, 1.5158, 1.2901, 1.5573, 0.6931, 1.0081, 0.6931, 2.1144,\n",
      "         1.4040, 1.5766, 1.7560]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 130/200\n",
      "tensor([[1.3930, 2.5999, 1.5160, 1.2845, 1.5564, 0.6931, 1.0013, 0.6931, 2.1168,\n",
      "         1.4054, 1.5726, 1.7574]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 131/200\n",
      "tensor([[1.3863, 2.6047, 1.5163, 1.2790, 1.5554, 0.6931, 0.9947, 0.6931, 2.1193,\n",
      "         1.4069, 1.5686, 1.7589]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 132/200\n",
      "tensor([[1.3796, 2.6096, 1.5167, 1.2736, 1.5545, 0.6931, 0.9881, 0.6931, 2.1218,\n",
      "         1.4085, 1.5648, 1.7605]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 133/200\n",
      "tensor([[1.3729, 2.6144, 1.5173, 1.2682, 1.5536, 0.6931, 0.9816, 0.6931, 2.1244,\n",
      "         1.4101, 1.5610, 1.7622]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 134/200\n",
      "tensor([[1.3661, 2.6191, 1.5180, 1.2628, 1.5528, 0.6931, 0.9751, 0.6931, 2.1269,\n",
      "         1.4118, 1.5573, 1.7640]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 135/200\n",
      "tensor([[1.3594, 2.6238, 1.5188, 1.2575, 1.5519, 0.6931, 0.9688, 0.6931, 2.1295,\n",
      "         1.4136, 1.5537, 1.7659]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 136/200\n",
      "tensor([[1.3527, 2.6284, 1.5198, 1.2522, 1.5510, 0.6931, 0.9625, 0.6931, 2.1321,\n",
      "         1.4154, 1.5501, 1.7679]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 137/200\n",
      "tensor([[1.3460, 2.6330, 1.5208, 1.2469, 1.5501, 0.6931, 0.9562, 0.6931, 2.1348,\n",
      "         1.4172, 1.5467, 1.7700]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 138/200\n",
      "tensor([[1.3393, 2.6376, 1.5220, 1.2416, 1.5492, 0.6931, 0.9501, 0.6931, 2.1374,\n",
      "         1.4191, 1.5432, 1.7721]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 139/200\n",
      "tensor([[1.3326, 2.6420, 1.5233, 1.2364, 1.5483, 0.6931, 0.9439, 0.6931, 2.1401,\n",
      "         1.4210, 1.5399, 1.7743]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 140/200\n",
      "tensor([[1.3260, 2.6465, 1.5247, 1.2312, 1.5474, 0.6931, 0.9378, 0.6931, 2.1427,\n",
      "         1.4229, 1.5366, 1.7766]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 141/200\n",
      "tensor([[1.3193, 2.6508, 1.5261, 1.2260, 1.5464, 0.6931, 0.9318, 0.6931, 2.1454,\n",
      "         1.4248, 1.5333, 1.7789]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 142/200\n",
      "tensor([[1.3126, 2.6551, 1.5277, 1.2208, 1.5455, 0.6931, 0.9258, 0.6931, 2.1481,\n",
      "         1.4267, 1.5302, 1.7814]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 143/200\n",
      "tensor([[1.3060, 2.6594, 1.5294, 1.2156, 1.5445, 0.6931, 0.9199, 0.6931, 2.1507,\n",
      "         1.4286, 1.5271, 1.7839]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 144/200\n",
      "tensor([[1.2994, 2.6636, 1.5311, 1.2104, 1.5434, 0.6931, 0.9140, 0.6931, 2.1534,\n",
      "         1.4306, 1.5240, 1.7864]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 145/200\n",
      "tensor([[1.2928, 2.6678, 1.5329, 1.2053, 1.5424, 0.6931, 0.9081, 0.6931, 2.1561,\n",
      "         1.4325, 1.5210, 1.7891]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 146/200\n",
      "tensor([[1.2862, 2.6719, 1.5348, 1.2001, 1.5413, 0.6931, 0.9023, 0.6931, 2.1588,\n",
      "         1.4344, 1.5181, 1.7918]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 147/200\n",
      "tensor([[1.2796, 2.6759, 1.5368, 1.1950, 1.5402, 0.6931, 0.8965, 0.6931, 2.1615,\n",
      "         1.4364, 1.5153, 1.7945]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 148/200\n",
      "tensor([[1.2731, 2.6799, 1.5389, 1.1898, 1.5390, 0.6931, 0.8908, 0.6931, 2.1641,\n",
      "         1.4383, 1.5125, 1.7974]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 149/200\n",
      "tensor([[1.2667, 2.6839, 1.5410, 1.1847, 1.5378, 0.6931, 0.8851, 0.6931, 2.1668,\n",
      "         1.4402, 1.5098, 1.8002]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 150/200\n",
      "tensor([[1.2602, 2.6878, 1.5433, 1.1795, 1.5366, 0.6931, 0.8794, 0.6931, 2.1695,\n",
      "         1.4420, 1.5072, 1.8032]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 151/200\n",
      "tensor([[1.2538, 2.6916, 1.5456, 1.1744, 1.5353, 0.6931, 0.8737, 0.6931, 2.1722,\n",
      "         1.4439, 1.5046, 1.8062]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 152/200\n",
      "tensor([[1.2475, 2.6954, 1.5479, 1.1693, 1.5340, 0.6931, 0.8681, 0.6931, 2.1748,\n",
      "         1.4458, 1.5021, 1.8093]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 153/200\n",
      "tensor([[1.2412, 2.6991, 1.5503, 1.1642, 1.5327, 0.6931, 0.8626, 0.6931, 2.1775,\n",
      "         1.4476, 1.4997, 1.8124]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 154/200\n",
      "tensor([[1.2350, 2.7028, 1.5528, 1.1591, 1.5313, 0.6931, 0.8570, 0.6931, 2.1801,\n",
      "         1.4494, 1.4973, 1.8155]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 155/200\n",
      "tensor([[1.2288, 2.7065, 1.5554, 1.1540, 1.5299, 0.6931, 0.8515, 0.6931, 2.1828,\n",
      "         1.4512, 1.4950, 1.8188]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 156/200\n",
      "tensor([[1.2227, 2.7101, 1.5580, 1.1489, 1.5284, 0.6931, 0.8460, 0.6931, 2.1854,\n",
      "         1.4529, 1.4928, 1.8220]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 157/200\n",
      "tensor([[1.2166, 2.7136, 1.5607, 1.1438, 1.5270, 0.6931, 0.8406, 0.6931, 2.1881,\n",
      "         1.4546, 1.4907, 1.8254]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 158/200\n",
      "tensor([[1.2106, 2.7171, 1.5635, 1.1387, 1.5254, 0.6931, 0.8352, 0.6931, 2.1907,\n",
      "         1.4563, 1.4886, 1.8287]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 159/200\n",
      "tensor([[1.2046, 2.7206, 1.5663, 1.1336, 1.5238, 0.6931, 0.8298, 0.6931, 2.1933,\n",
      "         1.4579, 1.4866, 1.8321]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 160/200\n",
      "tensor([[1.1988, 2.7240, 1.5691, 1.1286, 1.5222, 0.6931, 0.8245, 0.6931, 2.1959,\n",
      "         1.4595, 1.4847, 1.8356]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 161/200\n",
      "tensor([[1.1930, 2.7273, 1.5720, 1.1235, 1.5206, 0.6931, 0.8192, 0.6931, 2.1985,\n",
      "         1.4611, 1.4828, 1.8391]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 162/200\n",
      "tensor([[1.1872, 2.7306, 1.5750, 1.1185, 1.5189, 0.6931, 0.8139, 0.6931, 2.2011,\n",
      "         1.4626, 1.4811, 1.8426]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 163/200\n",
      "tensor([[1.1815, 2.7339, 1.5780, 1.1135, 1.5172, 0.6931, 0.8087, 0.6931, 2.2036,\n",
      "         1.4640, 1.4793, 1.8462]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 164/200\n",
      "tensor([[1.1759, 2.7371, 1.5811, 1.1085, 1.5154, 0.6931, 0.8035, 0.6931, 2.2062,\n",
      "         1.4654, 1.4777, 1.8498]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 165/200\n",
      "tensor([[1.1704, 2.7403, 1.5842, 1.1035, 1.5136, 0.6931, 0.7983, 0.6931, 2.2087,\n",
      "         1.4668, 1.4761, 1.8535]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 166/200\n",
      "tensor([[1.1649, 2.7434, 1.5873, 1.0985, 1.5117, 0.6931, 0.7931, 0.6931, 2.2112,\n",
      "         1.4681, 1.4746, 1.8571]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 167/200\n",
      "tensor([[1.1595, 2.7465, 1.5905, 1.0935, 1.5098, 0.6931, 0.7880, 0.6931, 2.2137,\n",
      "         1.4693, 1.4731, 1.8608]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 168/200\n",
      "tensor([[1.1542, 2.7495, 1.5938, 1.0885, 1.5079, 0.6931, 0.7829, 0.6931, 2.2162,\n",
      "         1.4705, 1.4717, 1.8645]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 169/200\n",
      "tensor([[1.1489, 2.7524, 1.5971, 1.0836, 1.5060, 0.6931, 0.7779, 0.6931, 2.2187,\n",
      "         1.4716, 1.4704, 1.8683]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 170/200\n",
      "tensor([[1.1437, 2.7553, 1.6004, 1.0786, 1.5040, 0.6931, 0.7729, 0.6931, 2.2212,\n",
      "         1.4727, 1.4691, 1.8720]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 171/200\n",
      "tensor([[1.1385, 2.7582, 1.6037, 1.0737, 1.5019, 0.6931, 0.7679, 0.6931, 2.2236,\n",
      "         1.4736, 1.4679, 1.8758]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 172/200\n",
      "tensor([[1.1334, 2.7610, 1.6071, 1.0688, 1.4999, 0.6931, 0.7629, 0.6931, 2.2260,\n",
      "         1.4745, 1.4668, 1.8796]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 173/200\n",
      "tensor([[1.1284, 2.7638, 1.6106, 1.0639, 1.4978, 0.6931, 0.7580, 0.6931, 2.2284,\n",
      "         1.4754, 1.4657, 1.8834]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 174/200\n",
      "tensor([[1.1234, 2.7665, 1.6140, 1.0591, 1.4957, 0.6931, 0.7531, 0.6931, 2.2308,\n",
      "         1.4761, 1.4646, 1.8873]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 175/200\n",
      "tensor([[1.1185, 2.7692, 1.6175, 1.0542, 1.4935, 0.6931, 0.7483, 0.6931, 2.2332,\n",
      "         1.4768, 1.4637, 1.8911]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 176/200\n",
      "tensor([[1.1137, 2.7718, 1.6210, 1.0494, 1.4913, 0.6931, 0.7435, 0.6931, 2.2355,\n",
      "         1.4774, 1.4627, 1.8950]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 177/200\n",
      "tensor([[1.1089, 2.7744, 1.6246, 1.0446, 1.4891, 0.6931, 0.7387, 0.6931, 2.2378,\n",
      "         1.4779, 1.4619, 1.8988]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 178/200\n",
      "tensor([[1.1041, 2.7769, 1.6282, 1.0398, 1.4869, 0.6931, 0.7340, 0.6931, 2.2401,\n",
      "         1.4784, 1.4611, 1.9027]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 179/200\n",
      "tensor([[1.0994, 2.7794, 1.6318, 1.0350, 1.4846, 0.6931, 0.7293, 0.6931, 2.2424,\n",
      "         1.4788, 1.4603, 1.9065]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 180/200\n",
      "tensor([[1.0948, 2.7818, 1.6354, 1.0303, 1.4824, 0.6931, 0.7247, 0.6931, 2.2446,\n",
      "         1.4790, 1.4596, 1.9104]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 181/200\n",
      "tensor([[1.0902, 2.7842, 1.6391, 1.0256, 1.4801, 0.6931, 0.7200, 0.6931, 2.2469,\n",
      "         1.4792, 1.4590, 1.9143]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 182/200\n",
      "tensor([[1.0857, 2.7865, 1.6427, 1.0209, 1.4777, 0.6931, 0.7155, 0.6931, 2.2491,\n",
      "         1.4793, 1.4584, 1.9182]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 183/200\n",
      "tensor([[1.0813, 2.7888, 1.6464, 1.0163, 1.4754, 0.6931, 0.7110, 0.6931, 2.2513,\n",
      "         1.4794, 1.4578, 1.9221]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 184/200\n",
      "tensor([[1.0768, 2.7911, 1.6501, 1.0117, 1.4730, 0.6931, 0.7065, 0.6931, 2.2534,\n",
      "         1.4793, 1.4574, 1.9259]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 185/200\n",
      "tensor([[1.0725, 2.7933, 1.6539, 1.0071, 1.4707, 0.6931, 0.7020, 0.6931, 2.2556,\n",
      "         1.4792, 1.4569, 1.9298]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 186/200\n",
      "tensor([[1.0681, 2.7954, 1.6576, 1.0025, 1.4683, 0.6931, 0.6976, 0.6931, 2.2577,\n",
      "         1.4789, 1.4566, 1.9337]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 187/200\n",
      "tensor([[1.0638, 2.7975, 1.6614, 0.9980, 1.4659, 0.6931, 0.6933, 0.6931, 2.2597,\n",
      "         1.4786, 1.4562, 1.9375]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 188/200\n",
      "tensor([[1.0596, 2.7996, 1.6652, 0.9936, 1.4635, 0.6931, 0.6890, 0.6931, 2.2618,\n",
      "         1.4782, 1.4560, 1.9414]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 189/200\n",
      "tensor([[1.0554, 2.8016, 1.6690, 0.9891, 1.4611, 0.6931, 0.6847, 0.6931, 2.2638,\n",
      "         1.4777, 1.4558, 1.9453]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 190/200\n",
      "tensor([[1.0512, 2.8036, 1.6728, 0.9847, 1.4587, 0.6931, 0.6805, 0.6931, 2.2658,\n",
      "         1.4771, 1.4556, 1.9491]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 191/200\n",
      "tensor([[1.0471, 2.8055, 1.6766, 0.9804, 1.4562, 0.6931, 0.6764, 0.6931, 2.2678,\n",
      "         1.4765, 1.4555, 1.9530]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 192/200\n",
      "tensor([[1.0430, 2.8074, 1.6804, 0.9760, 1.4538, 0.6931, 0.6723, 0.6931, 2.2697,\n",
      "         1.4757, 1.4555, 1.9568]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 193/200\n",
      "tensor([[1.0390, 2.8092, 1.6843, 0.9718, 1.4514, 0.6931, 0.6682, 0.6931, 2.2717,\n",
      "         1.4748, 1.4555, 1.9606]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 194/200\n",
      "tensor([[1.0350, 2.8110, 1.6881, 0.9675, 1.4490, 0.6931, 0.6642, 0.6931, 2.2735,\n",
      "         1.4739, 1.4555, 1.9644]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 195/200\n",
      "tensor([[1.0310, 2.8127, 1.6920, 0.9633, 1.4465, 0.6931, 0.6603, 0.6931, 2.2754,\n",
      "         1.4728, 1.4556, 1.9682]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 196/200\n",
      "tensor([[1.0270, 2.8144, 1.6958, 0.9592, 1.4441, 0.6931, 0.6564, 0.6931, 2.2772,\n",
      "         1.4717, 1.4558, 1.9720]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 197/200\n",
      "tensor([[1.0231, 2.8161, 1.6997, 0.9551, 1.4417, 0.6931, 0.6526, 0.6931, 2.2790,\n",
      "         1.4704, 1.4560, 1.9758]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 198/200\n",
      "tensor([[1.0192, 2.8177, 1.7036, 0.9510, 1.4393, 0.6931, 0.6488, 0.6931, 2.2808,\n",
      "         1.4691, 1.4563, 1.9796]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 199/200\n",
      "tensor([[1.0153, 2.8193, 1.7074, 0.9470, 1.4369, 0.6931, 0.6450, 0.6931, 2.2825,\n",
      "         1.4677, 1.4566, 1.9833]], grad_fn=<SoftplusBackward0>)\n",
      "Iter 200/200\n",
      "tensor([[1.0114, 2.8208, 1.7113, 0.9431, 1.4345, 0.6931, 0.6414, 0.6931, 2.2843,\n",
      "         1.4661, 1.4569, 1.9870]], grad_fn=<SoftplusBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "import os\n",
    "smoke_test = ('CI' in os.environ)\n",
    "training_iter = 2 if smoke_test else 200\n",
    "\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    # print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "    #     i + 1, training_iter, loss.item(),\n",
    "    #     model.covar_module.base_kernel.lengthscale.item(),\n",
    "    #     model.likelihood.noise.item()\n",
    "    # ))\n",
    "    print('Iter %d/%d' % (i + 1, training_iter))\n",
    "    print(model.covar_module.base_kernel.lengthscale)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get into evaluation (predictive posterior) mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.from_numpy(X_test_scaled).to(torch.float)\n",
    "    observed_pred_test = likelihood(model(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8790655301509265\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r_squared_sklearn_test = r2_score(edpResults[nn:, n], observed_pred_test.mean.numpy())\n",
    "print(r_squared_sklearn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\miniconda3\\envs\\torchenv310\\lib\\site-packages\\gpytorch\\models\\exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Get into evaluation (predictive posterior) mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    observed_pred_train = likelihood(model(train_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('likelihood.noise_covar.raw_noise', tensor([-2.6647])),\n",
       "             ('likelihood.noise_covar.raw_noise_constraint.lower_bound',\n",
       "              tensor(1.0000e-04)),\n",
       "             ('likelihood.noise_covar.raw_noise_constraint.upper_bound',\n",
       "              tensor(inf)),\n",
       "             ('mean_module.raw_constant', tensor(-4.6510)),\n",
       "             ('covar_module.raw_outputscale', tensor(2.0578)),\n",
       "             ('covar_module.base_kernel.raw_lengthscale',\n",
       "              tensor([[ 5.5329e-01,  2.7609e+00,  1.5168e+00,  4.4327e-01,  1.1592e+00,\n",
       "                       -1.7807e-23, -1.1410e-01, -2.6423e-20,  2.1787e+00,  1.2016e+00,\n",
       "                        1.1923e+00,  1.8439e+00]])),\n",
       "             ('covar_module.base_kernel.raw_lengthscale_constraint.lower_bound',\n",
       "              tensor(0.)),\n",
       "             ('covar_module.base_kernel.raw_lengthscale_constraint.upper_bound',\n",
       "              tensor(inf)),\n",
       "             ('covar_module.raw_outputscale_constraint.lower_bound',\n",
       "              tensor(0.)),\n",
       "             ('covar_module.raw_outputscale_constraint.upper_bound',\n",
       "              tensor(inf))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'ridr_model_state.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9703037082781684\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r_squared_sklearn_train = r2_score(edpResults[:nn, n], observed_pred_train.mean.numpy())\n",
    "print(r_squared_sklearn_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 生成示例数据（模拟预测值和观测值）\n",
    "np.random.seed(0)\n",
    "# observed_values = edpResults[:1600, 0]\n",
    "# predicted_values = observed_pred_train.mean.numpy()\n",
    "observed_values = np.exp(edpResults[nn:, n])\n",
    "predicted_values = np.exp(observed_pred_test.mean.numpy())\n",
    "# 绘制散点图和对角线\n",
    "a = 4\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(predicted_values, observed_values, color='blue', label='Data')\n",
    "plt.plot([0, a], [0, a], color='red', linestyle='--', label='Diagonal Line')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Observed Values')\n",
    "plt.xlim([0, 0.02])\n",
    "plt.ylim([0, 0.02])\n",
    "# plt.title('QQ Plot with Diagonal Line')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('pidr1_ob.txt', observed_values)\n",
    "np.savetxt('pidr1_pr.txt', predicted_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9830507029858789\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r_squared_sklearn_test = r2_score(observed_values, predicted_values)\n",
    "print(r_squared_sklearn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006007155710086807\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "MSE = mean_squared_error(observed_values, predicted_values)\n",
    "print(np.sqrt(MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # 生成示例数据（模拟预测值和观测值）\n",
    "# np.random.seed(0)\n",
    "# # observed_values = edpResults[:1600, 0]\n",
    "# # predicted_values = observed_pred_train.mean.numpy()\n",
    "# observed_values = np.exp(edpResults[:700, n])\n",
    "# predicted_values = np.exp(observed_pred_train.mean.numpy())\n",
    "# # 绘制散点图和对角线\n",
    "# a = 0.1\n",
    "# plt.figure(figsize=(4,4))\n",
    "# plt.scatter(predicted_values, observed_values, color='blue', label='Data')\n",
    "# plt.plot([0, a], [0, a], color='red', linestyle='--', label='Diagonal Line')\n",
    "# plt.xlabel('Predicted Values')\n",
    "# plt.ylabel('Observed Values')\n",
    "# plt.xlim([0, 0.04])\n",
    "# plt.ylim([0, 0.04])\n",
    "# # plt.title('QQ Plot with Diagonal Line')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
